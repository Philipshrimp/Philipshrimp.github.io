<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NeRF on Vision Shrimp</title>
    <link>https://Philipshrimp.github.io/posts/nerf/</link>
    <description>Recent content in NeRF on Vision Shrimp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Feb 2023 09:52:20 +0900</lastBuildDate><atom:link href="https://Philipshrimp.github.io/posts/nerf/index.xml" rel="self" type="application/rss+xml" /><item>
      <title>BARF : Bundle-Adjusting Neural Radiance Fields</title>
      <link>https://Philipshrimp.github.io/posts/nerf/barf/</link>
      <pubDate>Fri, 17 Feb 2023 09:52:20 +0900</pubDate>
      
      <guid>https://Philipshrimp.github.io/posts/nerf/barf/</guid>
      <description>해당 논문에 대한 리뷰 영상은 아래 동영상을 통해서도 확인하실 수 있습니다.   
Intro  
Original NeRF 논문은 처음 ECCV 2020에서 발표되었을 때, 뉴럴 렌더링 부분에 있어 굉장히 큰 화두가 되었다. 그와 동시에 많은 한계점들을 가지고 있어서 많은 연구자들로부터 그 문제점들이 지속적으로 지적되어 왔다. 이번에 리뷰할 BARF 논문에서는 그 중에서 Original NeRF가 입력 데이터로 정확한 Camera pose를 요구하고 있다는 점을 지적하고 있는데, 다시 말하면 입력 이미지 데이터와 한 쌍으로 있을 transformation 값이 부정확하거나 알 수 없을 경우에는 뉴럴 렌더링의 정확도가 떨어지게 된다는 것이다.</description>
    </item>
    
    
  </channel>
</rss>

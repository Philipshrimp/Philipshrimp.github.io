<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NeRF on Vision Shrimp</title>
    <link>https://Philipshrimp.github.io/posts/nerf/</link>
    <description>Recent content in NeRF on Vision Shrimp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Feb 2023 16:50:18 +0900</lastBuildDate><atom:link href="https://Philipshrimp.github.io/posts/nerf/index.xml" rel="self" type="application/rss+xml" /><item>
      <title>InfoNeRF: Ray Entropy Minimization for Few-Shot Neural Volume Rendering</title>
      <link>https://Philipshrimp.github.io/posts/nerf/infonerf/</link>
      <pubDate>Fri, 24 Feb 2023 16:50:18 +0900</pubDate>
      
      <guid>https://Philipshrimp.github.io/posts/nerf/infonerf/</guid>
      <description>이 논문은 적은 양의 입력으로도 NeRF를 수행할 수 있는 방법을 제안하고 있다. 위 동영상은 4장의 입력만으로 NeRF를 돌린 결과인데, 4장의 이미지에서 저런 일반화된 뉴럴 렌더링 결과가 나왔다는 사실이 굉장히 놀라웠다. 
Motivation 이 논문의 목적은 Entropy 개념을 이용하여 regularization을 시도하는 것이다. 다른 별도의 모듈을 추가하거나, 학습을 추가하는 등의 복잡한 기법을 추가한 것이 아닌 정보 이론 개념을 활용한 loss term 추가만으로 이를 가능하게 했다는 점이 핵심이며, 이 덕분에 다른 많은 NeRF 모듈에 해당 방법을 붙이기 쉽게 적용할 수 있다고 한다.</description>
    </item>
    
    <item>
      <title>BARF : Bundle-Adjusting Neural Radiance Fields</title>
      <link>https://Philipshrimp.github.io/posts/nerf/barf/</link>
      <pubDate>Fri, 17 Feb 2023 09:52:20 +0900</pubDate>
      
      <guid>https://Philipshrimp.github.io/posts/nerf/barf/</guid>
      <description>해당 논문에 대한 리뷰 영상은 아래 동영상을 통해서도 확인하실 수 있습니다.   
Intro  
Original NeRF 논문은 처음 ECCV 2020에서 발표되었을 때, 뉴럴 렌더링 부분에 있어 굉장히 큰 화두가 되었다. 그와 동시에 많은 한계점들을 가지고 있어서 많은 연구자들로부터 그 문제점들이 지속적으로 지적되어 왔다. 이번에 리뷰할 BARF 논문에서는 그 중에서 Original NeRF가 입력 데이터로 정확한 Camera pose를 요구하고 있다는 점을 지적하고 있는데, 다시 말하면 입력 이미지 데이터와 한 쌍으로 있을 transformation 값이 부정확하거나 알 수 없을 경우에는 뉴럴 렌더링의 정확도가 떨어지게 된다는 것이다.</description>
    </item>
    
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Vision Shrimp</title>
    <link>https://Philipshrimp.github.io/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Vision Shrimp</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Jul 2022 20:25:21 +0900</lastBuildDate><atom:link href="https://Philipshrimp.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" /><item>
      <title>CNN의 기본적인 구조 및 원리</title>
      <link>https://Philipshrimp.github.io/posts/neural_networks/cnn_basics/</link>
      <pubDate>Thu, 28 Jul 2022 20:25:21 +0900</pubDate>
      
      <guid>https://Philipshrimp.github.io/posts/neural_networks/cnn_basics/</guid>
      <description>처음 회사에서 인공지능 업무를 배정받기 이전에, 기본적인 CNN 구조에 대해 확실히 알고 가야 제대로 활용할 수 있겠다는 이야기를 듣고 CNN 구조부터 확실히 짚어가기 위해 기본적인 구조에 대한 학습을 시작했다.
이 포스트는 사내에서 세미나를 진행했던 CNN 기초를 다시 복습할 겸 저장하는 블로그 글이다.
Perceptron CNN이 본격적으로 활용되기 이전에 뉴럴 네트워크를 통해 image classification 등의 문제를 풀 때는 주로 perceptron 구조를 사용했다. 특정 차원의 벡터로 이루어진 입력이 들어오면 이 것을 여러 층의 hidden layer를 거쳐 출력 값을 내놓는 구조가 Multi layer perceptron이다.</description>
    </item>
    
    
  </channel>
</rss>
